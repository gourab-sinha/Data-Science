{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 149, 'Avengers: Infinity War']\n",
      "[2, 134, 'Black Panther']\n",
      "[3, 119, 'Deadpool 2']\n",
      "[4, 134, 'Bohemian Rhapsody']\n",
      "[5, 90, 'A Quiet Place']\n",
      "[6, 140, 'Ready Player One']\n",
      "[7, 143, 'Aquaman']\n",
      "[8, 112, 'Venom']\n",
      "[9, 117, 'Spider-Man: Into the Spider-Verse']\n",
      "[10, 136, 'A Star Is Born']\n",
      "[11, 130, 'Green Book']\n",
      "[12, 118, 'Ant-Man and the Wasp']\n",
      "[13, 147, 'Mission: Impossible - Fallout']\n",
      "[14, 135, 'Solo: A Star Wars Story']\n",
      "[15, 115, 'Annihilation']\n",
      "[16, 124, 'Bird Box']\n",
      "[17, 128, 'Jurassic World: Fallen Kingdom']\n",
      "[18, 118, 'Incredibles 2']\n",
      "[19, 127, 'Hereditary']\n",
      "[20, 134, 'Fantastic Beasts: The Crimes of Grindelwald']\n",
      "[21, 100, 'Game Night']\n",
      "[22, 135, 'BlacKkKlansman']\n",
      "[23, 119, 'Tomb Raider']\n",
      "[24, 110, \"Ocean's Eight\"]\n",
      "[25, 140, 'Red Sparrow']\n",
      "[26, 119, 'The Favourite']\n",
      "[27, 141, 'First Man']\n",
      "[28, 50, 'The Haunting of Hill House']\n",
      "[29, 113, 'The Meg']\n",
      "[30, 107, 'Rampage']\n",
      "[31, 100, 'Upgrade']\n",
      "[32, 135, 'Roma']\n",
      "[33, 101, 'Isle of Dogs']\n",
      "[34, 60, 'Altered Carbon']\n",
      "[35, 120, 'Crazy Rich Asians']\n",
      "[36, 102, 'Searching']\n",
      "[37, 114, 'Bumblebee']\n",
      "[38, 121, 'The Equalizer 2']\n",
      "[39, 112, 'Ralph Breaks the Internet: Wreck-It Ralph 2']\n",
      "[40, 141, 'Bad Times at the El Royale']\n",
      "[41, 122, 'Sicario 2: Soldado']\n",
      "[42, 45, 'You']\n",
      "[43, 117, 'A Simple Favor']\n",
      "[44, 107, 'The Predator']\n",
      "[45, 106, 'Halloween']\n",
      "[46, 96, 'The Nun']\n",
      "[47, 133, 'The Ballad of Buster Scruggs']\n",
      "[48, 90, 'Black Mirror: Bandersnatch']\n",
      "[49, 132, 'Vice']\n",
      "[50, 143, 'The Maze Runner: The Death Cure']\n",
      "[51, 100, 'Tag']\n",
      "[52, 111, 'Pacific Rim: Uprising']\n",
      "[53, 105, 'The Commuter']\n",
      "[54, 102, 'Skyscraper']\n",
      "[55, 130, 'Creed 2']\n",
      "[56, 128, 'Mortal Engines']\n",
      "[57, 116, 'The Mule']\n",
      "[58, 110, 'Love, Simon']\n",
      "[59, 102, 'The Cloverfield Paradox']\n",
      "[60, 140, 'Den of Thieves']\n",
      "[61, 60, 'Bodyguard']\n",
      "[62, 129, 'Widows']\n",
      "[63, 60, 'Jack Ryan']\n",
      "[64, 99, \"To All the Boys I've Loved Before\"]\n",
      "[65, 110, 'Overlord']\n",
      "[66, 114, 'Mamma Mia! Here We Go Again']\n",
      "[67, 130, 'Mary Poppins Returns']\n",
      "[68, 118, 'Instant Family']\n",
      "[69, 60, 'Lost in Space']\n",
      "[70, 50, 'Sacred Games']\n",
      "[71, 102, 'Blockers']\n",
      "[72, 60, 'Chilling Adventures of Sabrina']\n",
      "[73, 42, 'Killing Eve']\n",
      "[74, 104, 'Christopher Robin']\n",
      "[75, 117, 'The Spy Who Dumped Me']\n",
      "[76, 130, '12 Strong']\n",
      "[77, 94, 'Mile 22']\n",
      "[78, 40, 'Maniac']\n",
      "[79, 45, 'Titans']\n",
      "[80, 107, 'Death Wish']\n",
      "[81, 421, 'Sharp Objects']\n",
      "[82, 116, 'Robin Hood']\n",
      "[83, 139, 'Andhadhun']\n",
      "[84, 89, 'Johnny English Strikes Again']\n",
      "[85, 121, 'Mandy']\n",
      "[86, 110, 'Enes Batur Hayal mi Gerçek mi?']\n",
      "[87, 93, 'Eighth Grade']\n",
      "[88, 121, 'Outlaw King']\n",
      "[89, 112, 'Sorry to Bother You']\n",
      "[90, 104, 'Mowgli']\n",
      "[91, 105, 'The Kissing Booth']\n",
      "[92, 152, 'Suspiria']\n",
      "[93, 105, 'Fifty Shades Freed']\n",
      "[94, 97, 'Hotel Transylvania 3: Summer Vacation']\n",
      "[95, 96, 'Alpha']\n",
      "[96, 152, 'The House That Jack Built']\n",
      "[97, 103, 'Insidious: The Last Key']\n",
      "[98, 98, 'The First Purge']\n",
      "[99, 121, 'Shoplifters']\n",
      "[100, 95, 'Tully']\n",
      "[101, 50, 'Narcos: Mexico']\n",
      "[102, 122, 'Hunter Killer']\n",
      "[103, 122, 'Les frères Sisters']\n",
      "[104, 101, 'Peppermint']\n",
      "[105, 100, 'Free Solo']\n",
      "[106, 110, 'I Feel Pretty']\n",
      "[107, 155, 'Sanju']\n",
      "[108, 85, 'The Grinch']\n",
      "[109, 104, 'The Christmas Chronicles']\n",
      "[110, 123, 'Hotel Mumbai']\n",
      "[111, 120, 'Beautiful Boy']\n",
      "[112, 89, 'Zimna wojna']\n",
      "[113, 109, 'Leave No Trace']\n",
      "[114, 95, 'Extinction']\n",
      "[115, 106, 'Can You Ever Forgive Me?']\n",
      "[116, 113, 'How It Ends']\n",
      "[117, 96, 'Adrift']\n",
      "[118, 100, 'Truth or Dare']\n",
      "[119, 105, 'The House with a Clock in its Wall']\n",
      "[120, 126, 'Capharnaüm']\n",
      "[121, 97, 'Climax']\n",
      "[122, 30, 'Cobra Kai']\n",
      "[123, 109, 'A Wrinkle in Time']\n",
      "[124, 97, 'When We First Met']\n",
      "[125, 30, 'Disenchantment']\n",
      "[126, 94, 'Hotel Artemis']\n",
      "[127, 85, 'Mid90s']\n",
      "[128, 105, 'Set It Up']\n",
      "[129, 130, 'Apostle']\n",
      "[130, 98, 'Unsane']\n",
      "[131, 115, \"The Girl In The Spider's Web\"]\n",
      "[132, 148, 'Beoning']\n",
      "[133, 98, 'Arctic']\n",
      "[134, 93, 'The Old Man & The Gun']\n",
      "[135, 85, 'Den skyldige']\n",
      "[136, 119, 'If Beale Street Could Talk']\n",
      "[137, 41, 'O Mecanismo']\n",
      "[138, 30, 'Barry']\n",
      "[139, 116, 'American Animals']\n",
      "[140, 100, 'Anon']\n",
      "[141, 124, 'Mary Queen of Scots']\n",
      "[142, 60, 'The Terror']\n",
      "[143, 60, 'Castle Rock']\n",
      "[144, 60, 'The Alienist']\n",
      "[145, 95, 'Peter Rabbit']\n",
      "[146, 105, 'Sierra Burgess Is a Loser']\n",
      "[147, 160, 'Race 3']\n",
      "[148, 112, 'Overboard']\n",
      "[149, 125, 'Hold the Dark']\n",
      "[150, 111, 'Night School']\n",
      "[151, 125, 'Arif V 216']\n",
      "[152, 96, 'Smallfoot']\n",
      "[153, 105, 'Life of the Party']\n",
      "[154, 159, 'Dragged Across Concrete']\n",
      "[155, 90, 'The Perfection']\n",
      "[156, 156, 'K.G.F: Chapter 1']\n",
      "[157, 94, 'The Open House']\n",
      "[158, 30, 'Final Space']\n",
      "[159, 105, 'Summer of 84']\n",
      "[160, 126, 'Mute']\n",
      "[161, 40, 'The Protector']\n",
      "[162, 124, 'The Guernsey Literary and Potato Peel Pie Society']\n",
      "[163, 98, 'Stan & Ollie']\n",
      "[164, 60, 'Élite']\n",
      "[165, 99, 'Winchester']\n",
      "[166, 128, 'Durante la tormenta']\n",
      "[167, 139, 'Under the Silver Lake']\n",
      "[168, 122, 'Operation Finale']\n",
      "[169, 107, 'Replicas']\n",
      "[170, 115, 'Boy Erased']\n",
      "[171, 94, 'Braven']\n",
      "[172, 90, 'Holmes & Watson']\n",
      "[173, 97, 'The Titan']\n",
      "[174, 94, 'The 15:17 to Paris']\n",
      "[175, 104, 'The Darkest Minds']\n",
      "[176, 60, 'Safe']\n",
      "[177, 164, 'Padmaavat']\n",
      "[178, 99, 'The Nutcracker and the Four Realms']\n",
      "[179, 96, 'Escape Plan 2: Hades']\n",
      "[180, 133, 'Todos lo saben']\n",
      "[181, 133, 'The Hate U Give']\n",
      "[182, 110, \"Dumplin'\"]\n",
      "[183, 85, 'The Strangers: Prey at Night']\n",
      "[184, 45, 'The Rain']\n",
      "[185, 128, 'Stree']\n",
      "[186, 111, 'Gringo']\n",
      "[187, 101, 'Game Over, Man!']\n",
      "[188, 43, 'Good Girls']\n",
      "[189, 124, 'Badhaai ho']\n",
      "[190, 143, '22 July']\n",
      "[191, 60, 'Succession']\n",
      "[192, 99, 'They Shall Not Grow Old']\n",
      "[193, 93, 'Slender Man']\n",
      "[194, 97, 'Tau']\n",
      "[195, 134, 'Nada a Perder']\n",
      "[196, 111, \"At Eternity's Gate\"]\n",
      "[197, 99, 'Super Troopers 2']\n",
      "[198, 104, 'Book Club']\n",
      "[199, 164, 'Zero']\n",
      "[200, 95, 'Blindspotting']\n",
      "[201, 60, 'Mirzapur']\n",
      "[202, 111, 'White Boy Rick']\n",
      "[203, 113, 'High Life']\n",
      "[204, 60, 'A Discovery of Witches']\n",
      "[205, 91, 'The Happytime Murders']\n",
      "[206, 94, 'Cam']\n",
      "[207, 121, 'Destroyer']\n",
      "[208, 138, 'Raazi']\n",
      "[209, 87, 'Destination Wedding']\n",
      "[210, 60, 'Sahsiyet']\n",
      "[211, 91, 'Ghostland']\n",
      "[212, 60, 'Patrick Melrose']\n",
      "[213, 95, \"Won't You Be My Neighbor?\"]\n",
      "[214, 45, 'Insatiable']\n",
      "[215, 98, 'Greta']\n",
      "[216, 100, 'Dragon Ball Super: Broly']\n",
      "[217, 91, 'Midnight Sun']\n",
      "[218, 148, '2.0']\n",
      "[219, 96, 'Three Identical Strangers']\n",
      "[220, 403, 'Wild Wild Country']\n",
      "[221, 8, 'Bao']\n",
      "[222, 30, 'The Kominsky Method']\n",
      "[223, 110, 'Gräns']\n",
      "[224, 30, 'College Romance']\n",
      "[225, 105, 'Wildlife']\n",
      "[226, 103, 'Second Act']\n",
      "[227, 129, 'Parmanu: The Story of Pokhran']\n",
      "[228, 43, 'Black Lightning']\n",
      "[229, 120, 'On the Basis of Sex']\n",
      "[230, 104, 'Tumbbad']\n",
      "[231, 103, 'Dogman']\n",
      "[232, 114, \"Don't Worry, He Won't Get Far on Foot\"]\n",
      "[233, 43, 'Manifest']\n",
      "[234, 120, 'The Outsider']\n",
      "[235, 101, 'Calibre']\n",
      "[236, 192, \"Evil Genius: The True Story of America's Most Diabolical Bank Heist\"]\n",
      "[237, 92, 'Unfriended: Dark Web']\n",
      "[238, 140, 'Padman']\n",
      "[239, 138, 'Sonu Ke Titu Ki Sweety']\n",
      "[240, 89, 'Early Man']\n",
      "[241, 121, 'The Night Comes for Us']\n",
      "[242, 96, 'Traffik']\n",
      "[243, 101, 'The Princess Switch']\n",
      "[244, 103, 'The Hurricane Heist']\n",
      "[245, 43, '9-1-1']\n",
      "[246, 109, 'Beirut']\n",
      "[247, 98, 'Like Father']\n",
      "[248, 170, 'Rangasthalam']\n",
      "[249, 95, 'Terminal']\n",
      "[250, 30, 'Yeh Meri Family']\n"
     ]
    }
   ],
   "source": [
    "## URL : https://www.imdb.com/search/title?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt\n",
    "\n",
    "## Print the required output in given format\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "# class_ =\"lister-page-next next-page\"\n",
    "# class_ = \"lister-item-content\"\n",
    "base_url = \"https://www.imdb.com\"\n",
    "# class_ = \"lister-item-header\"\n",
    "\n",
    "all_urls = ['https://www.imdb.com/search/title?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt']\n",
    "j = 1\n",
    "movies_detail = []\n",
    "for i in range(4):\n",
    "    response = requests.get(all_urls[i])\n",
    "    data = BeautifulSoup(response.text,'html.parser')\n",
    "    next_page = data.find(class_ ='lister-page-next next-page')['href']\n",
    "    all_urls.append(str(base_url)+str(next_page))\n",
    "    # print(all_urls)\n",
    "    # print(type(next_page))\n",
    "    # print(type(all_urls))\n",
    "\n",
    "# print(movies_detail)\n",
    "\n",
    "\n",
    "# 1 = 50\n",
    "response = requests.get(all_urls[0])\n",
    "data = BeautifulSoup(response.text,'html.parser')\n",
    "movies = list(data.find_all(class_ = 'lister-item-content'))\n",
    "for i in movies:\n",
    "    name = i.find(class_ = 'lister-item-header').a.string\n",
    "    runtime = int(i.find(class_ = 'runtime').string.split()[0])\n",
    "    movies_detail.append([j,runtime,name])\n",
    "    j+=1\n",
    "\n",
    "# print(movies_detail)\n",
    "# print(\"##############\")\n",
    "    \n",
    "# 51 - 100\n",
    "response = requests.get(all_urls[1])\n",
    "data = BeautifulSoup(response.text,'html.parser')\n",
    "movies = list(data.find_all(class_ = 'lister-item-content'))\n",
    "for i in movies:\n",
    "    name = i.find(class_ = 'lister-item-header').a.string\n",
    "    runtime = int(i.find(class_ = 'runtime').string.split()[0])\n",
    "    movies_detail.append([j,runtime,name])\n",
    "    j+=1\n",
    "\n",
    "# print(movies_detail)\n",
    "# print(\"##############\")\n",
    "# 101 - 150\n",
    "response = requests.get(all_urls[2])\n",
    "data = BeautifulSoup(response.text,'html.parser')\n",
    "movies = list(data.find_all(class_ = 'lister-item-content'))\n",
    "for i in movies:\n",
    "    name = i.find(class_ = 'lister-item-header').a.string\n",
    "    runtime = int(i.find(class_ = 'runtime').string.split()[0])\n",
    "    movies_detail.append([j,runtime,name])\n",
    "    j+=1\n",
    "\n",
    "# print(movies_detail)\n",
    "# print(\"##############\")\n",
    "\n",
    "# # 151 - 200\n",
    "response = requests.get(all_urls[3])\n",
    "data = BeautifulSoup(response.text,'html.parser')\n",
    "movies = list(data.find_all(class_ = 'lister-item-content'))\n",
    "for i in movies:\n",
    "    name = i.find(class_ = 'lister-item-header').a.string\n",
    "    runtime = int(i.find(class_ = 'runtime').string.split()[0])\n",
    "    movies_detail.append([j,runtime,name])\n",
    "    j+=1\n",
    "\n",
    "    \n",
    "# # 201 - 250\n",
    "response = requests.get(all_urls[4])\n",
    "data = BeautifulSoup(response.text,'html.parser')\n",
    "movies = list(data.find_all(class_ = 'lister-item-content'))\n",
    "for i in movies:\n",
    "    name = i.find(class_ = 'lister-item-header').a.string\n",
    "    runtime = int(i.find(class_ = 'runtime').string.split()[0])\n",
    "    movies_detail.append([j,runtime,name])\n",
    "    j+=1\n",
    "\n",
    "# movies_detail.sort(reverse=True)\n",
    "for i in movies_detail:\n",
    "    print(i)\n",
    "# for i in movies_detail:\n",
    "#     print(i)\n",
    "# # for url in all_urls[:2]:\n",
    "# #     print(url)\n",
    "# #     response = requests.get(url)\n",
    "# #     # print(response.status_code)\n",
    "# #     data = BeautifulSoup(response.text,'html.parser')\n",
    "# #     movies = list(data.find_all(class_ = 'lister-item-content'))\n",
    "# #     for i in movies:\n",
    "# #         name = i.find(class_ = 'lister-item-header').a.string\n",
    "# #         runtime = int(i.find(class_ = 'runtime').string.split()[0])\n",
    "# #         print(name,runtime)\n",
    "# # #         movies_detail.append([name,runtime])\n",
    "    \n",
    "    \n",
    "# # # print(moives_detail)\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharp Objects 421\n",
      "Zero 164\n",
      "Padmaavat 164\n",
      "Race 3 160\n",
      "Dragged Across Concrete 159\n",
      "K.G.F: Chapter 1 156\n",
      "Sanju 155\n",
      "The House That Jack Built 152\n",
      "Suspiria 152\n",
      "Avengers: Infinity War 149\n",
      "Beoning 148\n",
      "Mission: Impossible - Fallout 147\n",
      "The Maze Runner: The Death Cure 143\n",
      "Aquaman 143\n",
      "22 July 143\n",
      "First Man 141\n",
      "Bad Times at the El Royale 141\n",
      "Red Sparrow 140\n",
      "Ready Player One 140\n",
      "Den of Thieves 140\n",
      "Under the Silver Lake 139\n",
      "Andhadhun 139\n",
      "A Star Is Born 136\n",
      "Solo: A Star Wars Story 135\n",
      "Roma 135\n",
      "BlacKkKlansman 135\n",
      "Nada a Perder 134\n",
      "Fantastic Beasts: The Crimes of Grindelwald 134\n",
      "Bohemian Rhapsody 134\n",
      "Black Panther 134\n",
      "Todos lo saben 133\n",
      "The Hate U Give 133\n",
      "The Ballad of Buster Scruggs 133\n",
      "Vice 132\n",
      "Mary Poppins Returns 130\n",
      "Green Book 130\n",
      "Creed 2 130\n",
      "Apostle 130\n",
      "12 Strong 130\n",
      "Widows 129\n",
      "Stree 128\n",
      "Mortal Engines 128\n",
      "Jurassic World: Fallen Kingdom 128\n",
      "Durante la tormenta 128\n",
      "Hereditary 127\n",
      "Mute 126\n",
      "Capharnaüm 126\n",
      "Hold the Dark 125\n",
      "Arif V 216 125\n",
      "The Guernsey Literary and Potato Peel Pie Society 124\n",
      "Mary Queen of Scots 124\n",
      "Bird Box 124\n",
      "Badhaai ho 124\n",
      "Hotel Mumbai 123\n",
      "Sicario 2: Soldado 122\n",
      "Operation Finale 122\n",
      "Les frères Sisters 122\n",
      "Hunter Killer 122\n",
      "The Equalizer 2 121\n",
      "Shoplifters 121\n",
      "Outlaw King 121\n",
      "Mandy 121\n",
      "Crazy Rich Asians 120\n",
      "Beautiful Boy 120\n",
      "Tomb Raider 119\n",
      "The Favourite 119\n",
      "If Beale Street Could Talk 119\n",
      "Deadpool 2 119\n",
      "Instant Family 118\n",
      "Incredibles 2 118\n",
      "Ant-Man and the Wasp 118\n",
      "The Spy Who Dumped Me 117\n",
      "Spider-Man: Into the Spider-Verse 117\n",
      "A Simple Favor 117\n",
      "The Mule 116\n",
      "Robin Hood 116\n",
      "American Animals 116\n",
      "The Girl In The Spider's Web 115\n",
      "Boy Erased 115\n",
      "Annihilation 115\n",
      "Mamma Mia! Here We Go Again 114\n",
      "Bumblebee 114\n",
      "The Meg 113\n",
      "How It Ends 113\n",
      "Venom 112\n",
      "Sorry to Bother You 112\n",
      "Ralph Breaks the Internet: Wreck-It Ralph 2 112\n",
      "Overboard 112\n",
      "Pacific Rim: Uprising 111\n",
      "Night School 111\n",
      "Gringo 111\n",
      "At Eternity's Gate 111\n",
      "Overlord 110\n",
      "Ocean's Eight 110\n",
      "Love, Simon 110\n",
      "I Feel Pretty 110\n",
      "Enes Batur Hayal mi Gerçek mi? 110\n",
      "Dumplin' 110\n",
      "Leave No Trace 109\n",
      "A Wrinkle in Time 109\n",
      "The Predator 107\n",
      "Replicas 107\n",
      "Rampage 107\n",
      "Death Wish 107\n",
      "Halloween 106\n",
      "Can You Ever Forgive Me? 106\n",
      "The Kissing Booth 105\n",
      "The House with a Clock in its Wall 105\n",
      "The Commuter 105\n",
      "Summer of 84 105\n",
      "Sierra Burgess Is a Loser 105\n",
      "Set It Up 105\n",
      "Life of the Party 105\n",
      "Fifty Shades Freed 105\n",
      "The Darkest Minds 104\n",
      "The Christmas Chronicles 104\n",
      "Mowgli 104\n",
      "Christopher Robin 104\n",
      "Book Club 104\n",
      "Insidious: The Last Key 103\n",
      "The Cloverfield Paradox 102\n",
      "Skyscraper 102\n",
      "Searching 102\n",
      "Blockers 102\n",
      "Peppermint 101\n",
      "Isle of Dogs 101\n",
      "Game Over, Man! 101\n",
      "Upgrade 100\n",
      "Truth or Dare 100\n",
      "Tag 100\n",
      "Game Night 100\n",
      "Free Solo 100\n",
      "Anon 100\n",
      "Winchester 99\n",
      "To All the Boys I've Loved Before 99\n",
      "They Shall Not Grow Old 99\n",
      "The Nutcracker and the Four Realms 99\n",
      "Super Troopers 2 99\n",
      "Unsane 98\n",
      "The First Purge 98\n",
      "Stan & Ollie 98\n",
      "Arctic 98\n",
      "When We First Met 97\n",
      "The Titan 97\n",
      "Tau 97\n",
      "Hotel Transylvania 3: Summer Vacation 97\n",
      "Climax 97\n",
      "The Nun 96\n",
      "Smallfoot 96\n",
      "Escape Plan 2: Hades 96\n",
      "Alpha 96\n",
      "Adrift 96\n",
      "Tully 95\n",
      "Peter Rabbit 95\n",
      "Extinction 95\n",
      "Blindspotting 95\n",
      "The Open House 94\n",
      "The 15:17 to Paris 94\n",
      "Mile 22 94\n",
      "Hotel Artemis 94\n",
      "Braven 94\n",
      "The Old Man & The Gun 93\n",
      "Slender Man 93\n",
      "Eighth Grade 93\n",
      "The Perfection 90\n",
      "Holmes & Watson 90\n",
      "Black Mirror: Bandersnatch 90\n",
      "A Quiet Place 90\n",
      "Zimna wojna 89\n",
      "Johnny English Strikes Again 89\n",
      "The Strangers: Prey at Night 85\n",
      "The Grinch 85\n",
      "Mid90s 85\n",
      "Den skyldige 85\n",
      "Élite 60\n",
      "The Terror 60\n",
      "The Alienist 60\n",
      "Succession 60\n",
      "Safe 60\n",
      "Lost in Space 60\n",
      "Jack Ryan 60\n",
      "Chilling Adventures of Sabrina 60\n",
      "Castle Rock 60\n",
      "Bodyguard 60\n",
      "Altered Carbon 60\n",
      "The Haunting of Hill House 50\n",
      "Sacred Games 50\n",
      "Narcos: Mexico 50\n",
      "You 45\n",
      "Titans 45\n",
      "The Rain 45\n",
      "Good Girls 43\n",
      "Killing Eve 42\n",
      "O Mecanismo 41\n",
      "The Protector 40\n",
      "Maniac 40\n",
      "Final Space 30\n",
      "Disenchantment 30\n",
      "Cobra Kai 30\n",
      "Barry 30\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "# class_ =\"lister-page-next next-page\"\n",
    "# class_ = \"lister-item-content\"\n",
    "base_url = \"https://www.imdb.com\"\n",
    "# class_ = \"lister-item-header\"\n",
    "\n",
    "current_url = 'https://www.imdb.com/search/title?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt'\n",
    "j = 1\n",
    "movies_detail = []\n",
    "for i in range(4):\n",
    "    response = requests.get(current_url)\n",
    "    data = BeautifulSoup(response.text,'html.parser')\n",
    "    movies = list(data.find_all(class_ = 'lister-item-content'))\n",
    "    for i in movies:\n",
    "        name = i.find(class_ = 'lister-item-header').a.string\n",
    "        runtime = int(i.find(class_ = 'runtime').string.split()[0])\n",
    "        movies_detail.append([runtime,name])\n",
    "\n",
    "    next_page = data.find(class_ ='lister-page-next next-page')['href']\n",
    "    current_url = (str(base_url)+str(next_page))\n",
    "\n",
    "movies_detail.sort(reverse=True)\n",
    "for i in movies_detail:\n",
    "    print(i[1],i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "“A day without sunshine is like, you know, night.”\n",
      "200\n",
      "200\n",
      "“Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.”\n",
      "“Beauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.”\n",
      "200\n",
      "“All you need is love. But a little chocolate now and then doesn't hurt.”\n",
      "200\n",
      "200\n",
      "200\n",
      "“Remember, we're madly in love, so it's all right to kiss me anytime you feel like it.”\n",
      "200\n",
      "“Some people never go crazy. What truly horrible lives they must lead.”\n",
      "“The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.”\n",
      "“Think left and think right and think low and think high. Oh, the thinks you can think up if only you try!”\n",
      "“The reason I talk to myself is because I’m the only one whose answers I accept.”\n",
      "“I am free of all prejudice. I hate everyone equally. ”\n",
      "200\n",
      "“A lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.”\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "## URL : http://quotes.toscrape.com/\n",
    "\n",
    "## Print the required output in given format\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "i = 1\n",
    "base_url = 'http://quotes.toscrape.com/page/{0}/'\n",
    "for i in range(11):\n",
    "    url = base_url.format(i)\n",
    "#     i+=1\n",
    "    # print(url)\n",
    "    response = requests.get(url)\n",
    "    print(response.status_code)\n",
    "    if response.status_code!=200:\n",
    "        print(\"Break\")\n",
    "        break\n",
    "    data = BeautifulSoup(response.text,'html.parser')    \n",
    "    get_list = data.find_all(class_ ='quote')\n",
    "    for i in get_list:\n",
    "        tags = i.find_all(class_ = 'tag')\n",
    "        for j in tags:\n",
    "            if \"humor\" == j.string:\n",
    "                # print(i.find(class_ = 'text').string + ' by ' + i.find(class_ = 'author').string)\n",
    "                print(i.find(class_ = 'text').string)\n",
    "                # print(i.find(class_ = 'text').string[1:-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albert Einstein\n",
      "Alexandre Dumas fils\n",
      "Alfred Tennyson\n",
      "Allen Saunders\n",
      "André Gide\n",
      "Bob Marley\n",
      "C.S. Lewis\n",
      "Charles Bukowski\n",
      "Charles M. Schulz\n",
      "Douglas Adams\n",
      "Dr. Seuss\n",
      "E.E. Cummings\n",
      "Eleanor Roosevelt\n",
      "Elie Wiesel\n",
      "Ernest Hemingway\n",
      "Friedrich Nietzsche\n",
      "Garrison Keillor\n",
      "George Bernard Shaw\n",
      "George Carlin\n",
      "George Eliot\n",
      "George R.R. Martin\n",
      "Harper Lee\n",
      "Haruki Murakami\n",
      "Helen Keller\n",
      "J.D. Salinger\n",
      "J.K. Rowling\n",
      "J.M. Barrie\n",
      "J.R.R. Tolkien\n",
      "James Baldwin\n",
      "Jane Austen\n",
      "Jim Henson\n",
      "Jimi Hendrix\n",
      "John Lennon\n",
      "Jorge Luis Borges\n",
      "Khaled Hosseini\n",
      "Madeleine L'Engle\n",
      "Marilyn Monroe\n",
      "Mark Twain\n",
      "Martin Luther King Jr.\n",
      "Mother Teresa\n",
      "Pablo Neruda\n",
      "Ralph Waldo Emerson\n",
      "Stephenie Meyer\n",
      "Steve Martin\n",
      "Suzanne Collins\n",
      "Terry Pratchett\n",
      "Thomas A. Edison\n",
      "W.C. Fields\n",
      "William Nicholson\n"
     ]
    }
   ],
   "source": [
    "## URL : http://quotes.toscrape.com/\n",
    "\n",
    "## Print the required output in given format\n",
    "## URL : http://quotes.toscrape.com/\n",
    "\n",
    "## Print the required output in given format\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "authors = []\n",
    "base_url = 'http://quotes.toscrape.com/page/{0}/'\n",
    "for i in range(11):\n",
    "    url = base_url.format(i)\n",
    "    \n",
    "    # print(url)\n",
    "    response = requests.get(url)\n",
    "    # print(response.status_code)\n",
    "    if response.status_code!=200:\n",
    "        break\n",
    "    data = BeautifulSoup(response.text,'html.parser')    \n",
    "    get_list = data.find_all(class_ ='quote')\n",
    "    for i in get_list:\n",
    "        tags = i.find_all(class_ = 'tag')\n",
    "        for j in tags:\n",
    "            authors.append(i.find(class_ = 'author').string)\n",
    "                \n",
    "    time.sleep(randint(0,3))\n",
    "\n",
    "setAuthors = set()\n",
    "for i in authors:\n",
    "    setAuthors.add(i)\n",
    "authors.clear()\n",
    "for i in setAuthors:\n",
    "    authors.append(i)\n",
    "authors.sort()\n",
    "for i in authors:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albert Einstein', 'March 14, 1879']\n",
      "['J.K. Rowling', 'July 31, 1965']\n",
      "['Jane Austen', 'December 16, 1775']\n",
      "['Marilyn Monroe', 'June 01, 1926']\n",
      "['André Gide', 'November 22, 1869']\n",
      "['Thomas A. Edison', 'February 11, 1847']\n",
      "['Eleanor Roosevelt', 'October 11, 1884']\n",
      "['Steve Martin', 'August 14, 1945']\n",
      "['Bob Marley', 'February 06, 1945']\n",
      "['Dr. Seuss', 'March 02, 1904']\n",
      "['Douglas Adams', 'March 11, 1952']\n",
      "['Elie Wiesel', 'September 30, 1928']\n",
      "['Friedrich Nietzsche', 'October 15, 1844']\n",
      "['Mark Twain', 'November 30, 1835']\n",
      "['Allen Saunders', 'April 24, 1899']\n",
      "['Pablo Neruda', 'July 12, 1904']\n",
      "['Ralph Waldo Emerson', 'May 25, 1803']\n",
      "['Mother Teresa', 'August 26, 1910']\n",
      "['Garrison Keillor', 'August 07, 1942']\n",
      "['Jim Henson', 'September 24, 1936']\n",
      "['Charles M. Schulz', 'November 26, 1922']\n",
      "['William Nicholson', 'January 12, 1948']\n",
      "['Jorge Luis Borges', 'August 24, 1899']\n",
      "['George Eliot', 'November 22, 1819']\n",
      "['George R.R. Martin', 'September 20, 1948']\n",
      "['C.S. Lewis', 'November 29, 1898']\n",
      "['Martin Luther King Jr.', 'January 15, 1929']\n",
      "['James Baldwin', 'August 02, 1924']\n",
      "['Haruki Murakami', 'January 12, 1949']\n",
      "['Alexandre Dumas-fils', 'July 27, 1824']\n",
      "['Stephenie Meyer', 'December 24, 1973']\n",
      "['Ernest Hemingway', 'July 21, 1899']\n",
      "['Helen Keller', 'June 27, 1880']\n",
      "['George Bernard Shaw', 'July 26, 1856']\n",
      "['Charles Bukowski', 'August 16, 1920']\n",
      "['Suzanne Collins', 'August 11, 1962']\n",
      "['J.R.R. Tolkien', 'January 03, 1892']\n",
      "['Alfred Tennyson', 'August 06, 1809']\n",
      "['Terry Pratchett', 'April 28, 1948']\n",
      "['J.D. Salinger', 'January 01, 1919']\n",
      "['George Carlin', 'May 12, 1937']\n",
      "['John Lennon', 'October 09, 1940']\n",
      "['W.C. Fields', 'January 29, 1880']\n",
      "['Ayn Rand', 'February 02, 1905']\n",
      "['Jimi Hendrix', 'November 27, 1942']\n",
      "['J.M. Barrie', 'May 09, 1860']\n",
      "['E.E. Cummings', 'October 14, 1894']\n",
      "['Khaled Hosseini', 'March 04, 1965']\n",
      "['Harper Lee', 'April 28, 1926']\n",
      "[\"Madeleine L'Engle\", 'November 29, 1918']\n"
     ]
    }
   ],
   "source": [
    "## URL : http://quotes.toscrape.com/\n",
    "\n",
    "## Print the required output in given format\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "authors_detail = {}\n",
    "base_url = 'http://quotes.toscrape.com/'\n",
    "current_page = 'http://quotes.toscrape.com'\n",
    "for i in range(11):\n",
    "    \n",
    "    # print(url)\n",
    "    response = requests.get(current_page)\n",
    "    # print(response.status_code)\n",
    "    if response.status_code!=200:\n",
    "        break\n",
    "    data = BeautifulSoup(response.text,'html.parser')  \n",
    "    authors = data.find_all(class_ = 'quote')\n",
    "    next_page = data.find(class_ = 'next')\n",
    "    for a in authors:\n",
    "        author = a.find(class_ = 'author')\n",
    "        authorname = author.string\n",
    "        author_link = \"\"\n",
    "        count = 0\n",
    "        for i in author.next_siblings:\n",
    "            if count!=1:\n",
    "                count+=1\n",
    "                continue\n",
    "            author_link = i['href']\n",
    "            break\n",
    "        if authorname not in authors_detail:\n",
    "            authors_detail[authorname] = author_link\n",
    "    if next_page is None:\n",
    "        break\n",
    "    current_page = base_url + next_page.a['href']\n",
    "                \n",
    "\n",
    "urls = []\n",
    "base_url = 'http://quotes.toscrape.com'\n",
    "for key,value in authors_detail.items():\n",
    "    # print(key,value)\n",
    "    url = base_url+value\n",
    "    urls.append(url)\n",
    "    # reponse = requests.get(url)\n",
    "    # print(response.status_code)\n",
    "    # data = BeautifulSoup(response.text,'html.parser')\n",
    "    # # dob = data.find(class_ ='author-born-date')\n",
    "    # print(data.find(class_ = 'author-born-date'))\n",
    "    # # authors.append({key:dob})\n",
    "    # break\n",
    "authors = []\n",
    "for i in urls:\n",
    "    response = requests.get(i)\n",
    "    data = BeautifulSoup(response.text,'html.parser')\n",
    "    name = data.find(class_ = 'author-title').string\n",
    "    dob = data.find(class_ = 'author-born-date').string\n",
    "    authors.append([name,dob])\n",
    "for i in authors:\n",
    "    print(i)\n",
    "    \n",
    "\n",
    "\n",
    "# print(len(authors.keys()))\n",
    "# names=sorted(authors)\n",
    "# for i in names:\n",
    "#     print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
